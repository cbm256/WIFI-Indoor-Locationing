{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import set_option\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19937, 529)\n"
     ]
    }
   ],
   "source": [
    "#data\n",
    "dataset = pd.read_csv(\"trainingData.csv\")\n",
    "\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WAP001                int64\n",
      "WAP002                int64\n",
      "WAP003                int64\n",
      "WAP004                int64\n",
      "WAP005                int64\n",
      "WAP006                int64\n",
      "WAP007                int64\n",
      "WAP008                int64\n",
      "WAP009                int64\n",
      "WAP010                int64\n",
      "WAP011                int64\n",
      "WAP012                int64\n",
      "                     ...   \n",
      "WAP518                int64\n",
      "WAP519                int64\n",
      "WAP520                int64\n",
      "LONGITUDE           float64\n",
      "LATITUDE            float64\n",
      "FLOOR                 int64\n",
      "BUILDINGID            int64\n",
      "SPACEID               int64\n",
      "RELATIVEPOSITION      int64\n",
      "USERID                int64\n",
      "PHONEID               int64\n",
      "TIMESTAMP             int64\n",
      "Length: 529, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# types\n",
    "set_option('display.max_rows', 25) \n",
    "print(dataset.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    WAP001  WAP002  WAP003  WAP004  WAP005  WAP006  WAP007  WAP008  WAP009  WAP010     ...      \\\n",
      "0      100     100     100     100     100     100     100     100     100     100     ...       \n",
      "1      100     100     100     100     100     100     100     100     100     100     ...       \n",
      "2      100     100     100     100     100     100     100     -97     100     100     ...       \n",
      "3      100     100     100     100     100     100     100     100     100     100     ...       \n",
      "4      100     100     100     100     100     100     100     100     100     100     ...       \n",
      "5      100     100     100     100     100     100     100     100     100     100     ...       \n",
      "6      100     100     100     100     100     100     100     100     100     100     ...       \n",
      "7      100     100     100     100     100     100     100     100     100     100     ...       \n",
      "8      100     100     100     100     100     100     100     100     100     100     ...       \n",
      "9      100     100     100     100     100     100     100     100     100     100     ...       \n",
      "10     100     100     100     100     100     100     100     -83     100     100     ...       \n",
      "11     100     100     100     100     100     100     100     -90     100     100     ...       \n",
      "12     100     100     100     100     100     100     100     100     100     100     ...       \n",
      "13     100     100     100     100     100     100     100     100     100     100     ...       \n",
      "14     100     100     100     100     100     100     100     100     100     100     ...       \n",
      "15     100     100     100     100     100     100     100     100     100     100     ...       \n",
      "16     100     100     100     100     100     100     100     100     100     100     ...       \n",
      "17     100     100     100     100     100     100     100     100     100     100     ...       \n",
      "18     100     100     100     100     100     100     100     100     100     100     ...       \n",
      "19     100     100     100     100     100     100     100     100     100     100     ...       \n",
      "\n",
      "    WAP520    LONGITUDE      LATITUDE  FLOOR  BUILDINGID  SPACEID  RELATIVEPOSITION  USERID  \\\n",
      "0      100 -7541.264300  4.864921e+06      2           1      106                 2       2   \n",
      "1      100 -7536.621200  4.864934e+06      2           1      106                 2       2   \n",
      "2      100 -7519.152400  4.864950e+06      2           1      103                 2       2   \n",
      "3      100 -7524.570400  4.864934e+06      2           1      102                 2       2   \n",
      "4      100 -7632.143600  4.864982e+06      0           0      122                 2      11   \n",
      "5      100 -7533.896200  4.864939e+06      2           1      105                 2       2   \n",
      "6      100 -7519.152400  4.864950e+06      2           1      103                 2       2   \n",
      "7      100 -7527.451100  4.864929e+06      2           1      101                 2       2   \n",
      "8      100 -7559.497300  4.864888e+06      2           1      112                 2       2   \n",
      "9      100 -7510.437173  4.864949e+06      2           1      103                 1       2   \n",
      "10     100 -7528.816402  4.864959e+06      2           1      104                 1       2   \n",
      "11     100 -7523.628200  4.864952e+06      2           1      104                 2       2   \n",
      "12     100 -7571.093400  4.864872e+06      2           1      110                 2       2   \n",
      "13     100 -7559.782000  4.864871e+06      2           1      108                 2       2   \n",
      "14     100 -7562.186200  4.864867e+06      2           1      109                 2       2   \n",
      "15     100 -7564.196300  4.864887e+06      2           1      111                 2       2   \n",
      "16     100 -7555.132300  4.864885e+06      2           1      107                 2       2   \n",
      "17     100 -7520.724500  4.864892e+06      2           1       15                 2       2   \n",
      "18     100 -7521.867186  4.864889e+06      2           1       29                 1       2   \n",
      "19     100 -7537.339900  4.864896e+06      2           1      117                 2       2   \n",
      "\n",
      "    PHONEID   TIMESTAMP  \n",
      "0        23  1371713733  \n",
      "1        23  1371713691  \n",
      "2        23  1371714095  \n",
      "3        23  1371713807  \n",
      "4        13  1369909710  \n",
      "5        23  1371713841  \n",
      "6        23  1371713883  \n",
      "7        23  1371713775  \n",
      "8        23  1371714307  \n",
      "9        23  1371714128  \n",
      "10       23  1371714200  \n",
      "11       23  1371714166  \n",
      "12       23  1371714393  \n",
      "13       23  1371714467  \n",
      "14       23  1371714433  \n",
      "15       23  1371714355  \n",
      "16       23  1371714509  \n",
      "17       23  1371714730  \n",
      "18       23  1371714802  \n",
      "19       23  1371714556  \n",
      "\n",
      "[20 rows x 529 columns]\n"
     ]
    }
   ],
   "source": [
    "# head\n",
    "set_option('display.width', 100) \n",
    "print(dataset.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FLOOR</th>\n",
       "      <th>BUILDINGID</th>\n",
       "      <th>SPACEID</th>\n",
       "      <th>RELATIVEPOSITION</th>\n",
       "      <th>USERID</th>\n",
       "      <th>PHONEID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>19937</td>\n",
       "      <td>19937</td>\n",
       "      <td>19937</td>\n",
       "      <td>19937</td>\n",
       "      <td>19937</td>\n",
       "      <td>19937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>123</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>202</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5048</td>\n",
       "      <td>9492</td>\n",
       "      <td>484</td>\n",
       "      <td>16608</td>\n",
       "      <td>4516</td>\n",
       "      <td>4835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        FLOOR BUILDINGID SPACEID RELATIVEPOSITION USERID PHONEID\n",
       "count   19937      19937   19937            19937  19937   19937\n",
       "unique      5          3     123                2     18      16\n",
       "top         3          2     202                2     11      14\n",
       "freq     5048       9492     484            16608   4516    4835"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Response variables in our problem are Building, Floor, Latitude, Longitude and Relative Position\n",
    "(dataset[['FLOOR','BUILDINGID', 'SPACEID','RELATIVEPOSITION','USERID','PHONEID']]\n",
    ".astype(str)\n",
    ".describe(include=['object']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Focusing on Floor BuildingID and SpaceID predicted on 520 WAPs on 3 buildings so delete other variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dataset ['LONGITUDE']\n",
    "del dataset ['LATITUDE']\n",
    "del dataset ['RELATIVEPOSITION']\n",
    "del dataset ['USERID']\n",
    "del dataset ['PHONEID']\n",
    "del dataset ['TIMESTAMP']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WAP001        int64\n",
      "WAP002        int64\n",
      "WAP003        int64\n",
      "WAP004        int64\n",
      "WAP005        int64\n",
      "WAP006        int64\n",
      "WAP007        int64\n",
      "WAP008        int64\n",
      "WAP009        int64\n",
      "WAP010        int64\n",
      "WAP011        int64\n",
      "WAP012        int64\n",
      "              ...  \n",
      "WAP512        int64\n",
      "WAP513        int64\n",
      "WAP514        int64\n",
      "WAP515        int64\n",
      "WAP516        int64\n",
      "WAP517        int64\n",
      "WAP518        int64\n",
      "WAP519        int64\n",
      "WAP520        int64\n",
      "FLOOR         int64\n",
      "BUILDINGID    int64\n",
      "SPACEID       int64\n",
      "Length: 523, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(dataset.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19937, 523)\n"
     ]
    }
   ],
   "source": [
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.hist(dataset['BUILDINGID'])\n",
    "pyplot.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.hist(dataset['FLOOR'])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAFJ1JREFUeJzt3X+MXeWd3/H3ZyGwm2waGxgQtU3tNNZ2SaUQOgK3qaI2bI2Bak2lIJFWxUKW3D/YNqlatab7h1NIJKjaZYu6QXIXtyZKQyibCGuhSyyHaFWp/DCBEMBLPQEWvHaxszZkt3TZwH77x30muTgznjv2eG6Y5/2Srs453/Oce55Hx/Jnzo97b6oKSVJ/fm7cHZAkjYcBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjo1UgAk+edJnkvybJKvJvn5JGuSPJZkf5KvJTmrtT27LU+19auH3ufmVn8hyZWnZ0iSpFHMGQBJVgD/DJisqr8OnAFcD9wO3FFVa4FjwOa2yWbgWFV9BLijtSPJxW27jwIbgC8lOWNhhyNJGtWZ82j3C0l+BLwfOAR8CviHbf1O4PPAXcDGNg9wP/CfkqTV762qt4CXkkwBlwH/a7adnnfeebV69ep5DEeS9OSTT/6gqibmajdnAFTVHyX598ArwP8Dvgk8CbxeVW+3ZgeAFW1+BfBq2/btJG8A57b6o0NvPbzNjFavXs3evXvn6qIkaUiSPxyl3SiXgJYz+Ot9DfCXgQ8AV83QdPpLhTLLutnqx+9vS5K9SfYeOXJkru5Jkk7SKDeBfwV4qaqOVNWPgK8DfwtYlmT6DGIlcLDNHwBWAbT1HwKODtdn2ObHqmp7VU1W1eTExJxnMJKkkzRKALwCrEvy/nYt/wrgeeAR4NOtzSbggTa/qy3T1n+rBl85ugu4vj0ltAZYCzy+MMOQJM3XKPcAHktyP/Ad4G3gKWA78CBwb5IvtNrdbZO7gS+3m7xHGTz5Q1U9l+Q+BuHxNnBTVb2zwOORJI0oP8u/BzA5OVneBJak+UnyZFVNztXOTwJLUqcMAEnqlAEgSZ0yACSpU6N+FYT0M2n11gfHtu+Xb7tmbPuWFoJnAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ2aMwCS/FKSp4deP0zyuSTnJNmdZH+bLm/tk+TOJFNJnkly6dB7bWrt9yfZNPteJUmn25wBUFUvVNUlVXUJ8DeAN4FvAFuBPVW1FtjTlgGuAta21xbgLoAk5wDbgMuBy4Bt06EhSVp8870EdAXw/ar6Q2AjsLPVdwLXtvmNwD018CiwLMmFwJXA7qo6WlXHgN3AhlMegSTppMw3AK4HvtrmL6iqQwBten6rrwBeHdrmQKvNVpckjcHIAZDkLOBXgf8+V9MZanWC+vH72ZJkb5K9R44cGbV7kqR5ms8ZwFXAd6rqtbb8Wru0Q5sebvUDwKqh7VYCB09Qf5eq2l5Vk1U1OTExMY/uSZLmYz4B8Bl+cvkHYBcw/STPJuCBofoN7WmgdcAb7RLRw8D6JMvbzd/1rSZJGoORfhQ+yfuBvwf8k6HybcB9STYDrwDXtfpDwNXAFIMnhm4EqKqjSW4Fnmjtbqmqo6c8AknSSRkpAKrqTeDc42p/zOCpoOPbFnDTLO+zA9gx/25KkhaanwSWpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktSpkQIgybIk9yf5gyT7kvzNJOck2Z1kf5sub22T5M4kU0meSXLp0Ptsau33J9k0+x4lSafbqGcA/xH4var6a8DHgH3AVmBPVa0F9rRlgKuAte21BbgLIMk5wDbgcuAyYNt0aEiSFt+cAZDkLwGfBO4GqKo/r6rXgY3AztZsJ3Btm98I3FMDjwLLklwIXAnsrqqjVXUM2A1sWNDRSJJGNsoZwIeBI8B/SfJUkt9O8gHggqo6BNCm57f2K4BXh7Y/0Gqz1SVJYzBKAJwJXArcVVUfB/4vP7ncM5PMUKsT1N+9cbIlyd4ke48cOTJC9yRJJ2OUADgAHKiqx9ry/QwC4bV2aYc2PTzUftXQ9iuBgyeov0tVba+qyaqanJiYmM9YJEnzMGcAVNX/AV5N8kutdAXwPLALmH6SZxPwQJvfBdzQngZaB7zRLhE9DKxPsrzd/F3fapKkMThzxHb/FPhKkrOAF4EbGYTHfUk2A68A17W2DwFXA1PAm60tVXU0ya3AE63dLVV1dEFGIUmat5ECoKqeBiZnWHXFDG0LuGmW99kB7JhPByVJp4efBJakThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1KmRAiDJy0m+l+TpJHtb7Zwku5Psb9PlrZ4kdyaZSvJMkkuH3mdTa78/yabZ9idJOv3mcwbwd6vqkqqa/m3grcCeqloL7GnLAFcBa9trC3AXDAID2AZcDlwGbJsODUnS4juVS0AbgZ1tfidw7VD9nhp4FFiW5ELgSmB3VR2tqmPAbmDDKexfknQKRg2AAr6Z5MkkW1rtgqo6BNCm57f6CuDVoW0PtNpsdUnSGJw5YrtPVNXBJOcDu5P8wQnaZoZanaD+7o0HAbMF4KKLLhqxe5Kk+RrpDKCqDrbpYeAbDK7hv9Yu7dCmh1vzA8Cqoc1XAgdPUD9+X9urarKqJicmJuY3GknSyOYMgCQfSPLB6XlgPfAssAuYfpJnE/BAm98F3NCeBloHvNEuET0MrE+yvN38Xd9qkqQxGOUS0AXAN5JMt/9vVfV7SZ4A7kuyGXgFuK61fwi4GpgC3gRuBKiqo0luBZ5o7W6pqqMLNhJJ0rzMGQBV9SLwsRnqfwxcMUO9gJtmea8dwI75d1OStND8JLAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktSpUX8PQJLGZvXWB8ey35dvu2Ys+10sngFIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkTo0cAEnOSPJUkt9ty2uSPJZkf5KvJTmr1c9uy1Nt/eqh97i51V9IcuVCD0aSNLr5nAF8Ftg3tHw7cEdVrQWOAZtbfTNwrKo+AtzR2pHkYuB64KPABuBLSc44te5Lkk7WSAGQZCVwDfDbbTnAp4D7W5OdwLVtfmNbpq2/orXfCNxbVW9V1UvAFHDZQgxCkjR/o54B/Cbwr4C/aMvnAq9X1dtt+QCwos2vAF4FaOvfaO1/XJ9hG0nSIpszAJL8feBwVT05XJ6hac2x7kTbDO9vS5K9SfYeOXJkru5Jkk7SKGcAnwB+NcnLwL0MLv38JrAsyfR3Ca0EDrb5A8AqgLb+Q8DR4foM2/xYVW2vqsmqmpyYmJj3gCRJo5kzAKrq5qpaWVWrGdzE/VZV/SPgEeDTrdkm4IE2v6st09Z/q6qq1a9vTwmtAdYCjy/YSCRJ83Iq3wb6r4F7k3wBeAq4u9XvBr6cZIrBX/7XA1TVc0nuA54H3gZuqqp3TmH/kqRTMK8AqKpvA99u8y8yw1M8VfVnwHWzbP9F4Ivz7aQkaeH5SWBJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqdO5RfBpK6t3vrgWPb78m3XjGW/Wno8A5CkTs0ZAEl+PsnjSb6b5Lkk/7bV1yR5LMn+JF9Lclarn92Wp9r61UPvdXOrv5DkytM1KEnS3EY5A3gL+FRVfQy4BNiQZB1wO3BHVa0FjgGbW/vNwLGq+ghwR2tHkosZ/ED8R4ENwJeSnLGQg5EkjW7OAKiBP22L72uvAj4F3N/qO4Fr2/zGtkxbf0WStPq9VfVWVb0ETDHDj8pLkhbHSPcAkpyR5GngMLAb+D7welW93ZocAFa0+RXAqwBt/RvAucP1GbaRJC2ykQKgqt6pqkuAlQz+av/lmZq1aWZZN1v9XZJsSbI3yd4jR46M0j1J0kmY11NAVfU68G1gHbAsyfRjpCuBg23+ALAKoK3/EHB0uD7DNsP72F5Vk1U1OTExMZ/uSZLmYZSngCaSLGvzvwD8CrAPeAT4dGu2CXigze9qy7T136qqavXr21NCa4C1wOMLNRBJ0vyM8kGwC4Gd7YmdnwPuq6rfTfI8cG+SLwBPAXe39ncDX04yxeAv/+sBquq5JPcBzwNvAzdV1TsLOxxJ0qjmDICqegb4+Az1F5nhKZ6q+jPgulne64vAF+ffTUnSQvOTwJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOjXKj8KvSvJIkn1Jnkvy2VY/J8nuJPvbdHmrJ8mdSaaSPJPk0qH32tTa70+yabZ9SpJOv1HOAN4G/kVV/TKwDrgpycXAVmBPVa0F9rRlgKuAte21BbgLBoEBbAMuZ/BbwtumQ0OStPjmDICqOlRV32nzfwLsA1YAG4GdrdlO4No2vxG4pwYeBZYluRC4EthdVUer6hiwG9iwoKORJI1sXvcAkqwGPg48BlxQVYdgEBLA+a3ZCuDVoc0OtNpsdUnSGIwcAEl+Efgd4HNV9cMTNZ2hVieoH7+fLUn2Jtl75MiRUbsnSZqnkQIgyfsY/Of/lar6eiu/1i7t0KaHW/0AsGpo85XAwRPU36WqtlfVZFVNTkxMzGcskqR5GOUpoAB3A/uq6jeGVu0Cpp/k2QQ8MFS/oT0NtA54o10iehhYn2R5u/m7vtUkSWNw5ghtPgH8Y+B7SZ5utX8D3Abcl2Qz8ApwXVv3EHA1MAW8CdwIUFVHk9wKPNHa3VJVRxdkFJKkeZszAKrqfzLz9XuAK2ZoX8BNs7zXDmDHfDooSTo9/CSwJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdGuWDYJLUpdVbHxzbvl++7ZrTvg/PACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pSfA5A0snE+F6+F5xmAJHXKAJCkTo3yo/A7khxO8uxQ7Zwku5Psb9PlrZ4kdyaZSvJMkkuHttnU2u9PsmmmfUmSFs8oZwD/FdhwXG0rsKeq1gJ72jLAVcDa9toC3AWDwAC2AZcDlwHbpkNDkjQecwZAVf0+cPS48kZgZ5vfCVw7VL+nBh4FliW5ELgS2F1VR6vqGLCbnw4VSdIiOtl7ABdU1SGANj2/1VcArw61O9Bqs9UlSWOy0I+BZoZanaD+02+QbGFw+YiLLrrolDozrkfWFuNrXCXpVJ3sGcBr7dIObXq41Q8Aq4barQQOnqD+U6pqe1VNVtXkxMTESXZPkjSXkw2AXcD0kzybgAeG6je0p4HWAW+0S0QPA+uTLG83f9e3miRpTOa8BJTkq8DfAc5LcoDB0zy3Afcl2Qy8AlzXmj8EXA1MAW8CNwJU1dEktwJPtHa3VNXxN5YlSYtozgCoqs/MsuqKGdoWcNMs77MD2DGv3uk9w68IkN57/CSwJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROLXoAJNmQ5IUkU0m2Lvb+JUkDixoASc4Afgu4CrgY+EySixezD5KkgTl/FH6BXQZMVdWLAEnuBTYCzy9yP06rcf1A+su3XTOW/Up6b1rsS0ArgFeHlg+0miRpkS32GUBmqNW7GiRbgC1t8U+TvHAS+zkP+MFJbPdedR7wg9w+7m4sqi6PMUAnx7nb4zvtFI/zXxml0WIHwAFg1dDySuDgcIOq2g5sP5WdJNlbVZOn8h7vJb2NF/obs+Nd2sY13sW+BPQEsDbJmiRnAdcDuxa5D5IkFvkMoKreTvJrwMPAGcCOqnpuMfsgSRpY7EtAVNVDwEOneTendAnpPai38UJ/Y3a8S9tYxpuqmruVJGnJ8asgJKlTSy4AeviqiSQvJ/lekqeT7G21c5LsTrK/TZePu58nK8mOJIeTPDtUm3F8GbizHe9nklw6vp6fnFnG+/kkf9SO8dNJrh5ad3Mb7wtJrhxPr09eklVJHkmyL8lzST7b6kvyGJ9gvOM/xlW1ZF4Mbix/H/gwcBbwXeDicffrNIzzZeC842r/Dtja5rcCt4+7n6cwvk8ClwLPzjU+4GrgfzD4jMk64LFx93+Bxvt54F/O0Pbi9u/6bGBN+/d+xrjHMM/xXghc2uY/CPzvNq4leYxPMN6xH+Oldgbw46+aqKo/B6a/aqIHG4GdbX4ncO0Y+3JKqur3gaPHlWcb30bgnhp4FFiW5MLF6enCmGW8s9kI3FtVb1XVS8AUg3/37xlVdaiqvtPm/wTYx+AbAZbkMT7BeGezaMd4qQVAL181UcA3kzzZPjkNcEFVHYLBPzjg/LH17vSYbXxL+Zj/WrvksWPokt6SGm+S1cDHgcfo4BgfN14Y8zFeagEw51dNLBGfqKpLGXyr6k1JPjnuDo3RUj3mdwF/FbgEOAT8h1ZfMuNN8ovA7wCfq6ofnqjpDLX33JhnGO/Yj/FSC4A5v2piKaiqg216GPgGg9PD16ZPi9v08Ph6eFrMNr4lecyr6rWqeqeq/gL4z/zkEsCSGG+S9zH4z/ArVfX1Vl6yx3im8f4sHOOlFgBL/qsmknwgyQen54H1wLMMxrmpNdsEPDCeHp42s41vF3BDe1JkHfDG9GWE97LjrnH/AwbHGAbjvT7J2UnWAGuBxxe7f6ciSYC7gX1V9RtDq5bkMZ5tvD8Tx3jcd8hPwx33qxncZf8+8Ovj7s9pGN+HGTwh8F3guekxAucCe4D9bXrOuPt6CmP8KoNT4h8x+Gto82zjY3C6/FvteH8PmBx3/xdovF9u43mGwX8IFw61//U23heAq8bd/5MY799mcEnjGeDp9rp6qR7jE4x37MfYTwJLUqeW2iUgSdKIDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjr1/wELucGzOsPD5AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.hist(dataset['SPACEID'])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of feature sample\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WAP001</th>\n",
       "      <th>WAP002</th>\n",
       "      <th>WAP003</th>\n",
       "      <th>WAP004</th>\n",
       "      <th>WAP005</th>\n",
       "      <th>WAP006</th>\n",
       "      <th>WAP007</th>\n",
       "      <th>WAP008</th>\n",
       "      <th>WAP009</th>\n",
       "      <th>WAP010</th>\n",
       "      <th>...</th>\n",
       "      <th>WAP511</th>\n",
       "      <th>WAP512</th>\n",
       "      <th>WAP513</th>\n",
       "      <th>WAP514</th>\n",
       "      <th>WAP515</th>\n",
       "      <th>WAP516</th>\n",
       "      <th>WAP517</th>\n",
       "      <th>WAP518</th>\n",
       "      <th>WAP519</th>\n",
       "      <th>WAP520</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>-97</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 520 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   WAP001  WAP002  WAP003  WAP004  WAP005  WAP006  WAP007  WAP008  WAP009  WAP010   ...    WAP511  \\\n",
       "0     100     100     100     100     100     100     100     100     100     100   ...       100   \n",
       "1     100     100     100     100     100     100     100     100     100     100   ...       100   \n",
       "2     100     100     100     100     100     100     100     -97     100     100   ...       100   \n",
       "3     100     100     100     100     100     100     100     100     100     100   ...       100   \n",
       "4     100     100     100     100     100     100     100     100     100     100   ...       100   \n",
       "\n",
       "   WAP512  WAP513  WAP514  WAP515  WAP516  WAP517  WAP518  WAP519  WAP520  \n",
       "0     100     100     100     100     100     100     100     100     100  \n",
       "1     100     100     100     100     100     100     100     100     100  \n",
       "2     100     100     100     100     100     100     100     100     100  \n",
       "3     100     100     100     100     100     100     100     100     100  \n",
       "4     100     100     100     100     100     100     100     100     100  \n",
       "\n",
       "[5 rows x 520 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#features\n",
    "features = dataset.iloc[:,0:520]\n",
    "print('Summary of feature sample')\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    106\n",
       "1    106\n",
       "2    103\n",
       "3    102\n",
       "4    122\n",
       "Name: SPACEID, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dependent variable\n",
    "depVar = dataset['SPACEID']\n",
    "depVar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WAP001</th>\n",
       "      <th>WAP002</th>\n",
       "      <th>WAP003</th>\n",
       "      <th>WAP004</th>\n",
       "      <th>WAP005</th>\n",
       "      <th>WAP006</th>\n",
       "      <th>WAP007</th>\n",
       "      <th>WAP008</th>\n",
       "      <th>WAP009</th>\n",
       "      <th>WAP010</th>\n",
       "      <th>...</th>\n",
       "      <th>WAP511</th>\n",
       "      <th>WAP512</th>\n",
       "      <th>WAP513</th>\n",
       "      <th>WAP514</th>\n",
       "      <th>WAP515</th>\n",
       "      <th>WAP516</th>\n",
       "      <th>WAP517</th>\n",
       "      <th>WAP518</th>\n",
       "      <th>WAP519</th>\n",
       "      <th>WAP520</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>-97</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 520 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   WAP001  WAP002  WAP003  WAP004  WAP005  WAP006  WAP007  WAP008  WAP009  WAP010   ...    WAP511  \\\n",
       "0     100     100     100     100     100     100     100     100     100     100   ...       100   \n",
       "1     100     100     100     100     100     100     100     100     100     100   ...       100   \n",
       "2     100     100     100     100     100     100     100     -97     100     100   ...       100   \n",
       "3     100     100     100     100     100     100     100     100     100     100   ...       100   \n",
       "4     100     100     100     100     100     100     100     100     100     100   ...       100   \n",
       "\n",
       "   WAP512  WAP513  WAP514  WAP515  WAP516  WAP517  WAP518  WAP519  WAP520  \n",
       "0     100     100     100     100     100     100     100     100     100  \n",
       "1     100     100     100     100     100     100     100     100     100  \n",
       "2     100     100     100     100     100     100     100     100     100  \n",
       "3     100     100     100     100     100     100     100     100     100  \n",
       "4     100     100     100     100     100     100     100     100     100  \n",
       "\n",
       "[5 rows x 520 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training Set (Feature Space: X Training)\n",
    "X_train = (features[: 1000])\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of observations in the Y training set are: 1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    106\n",
       "1    106\n",
       "2    103\n",
       "3    102\n",
       "4    122\n",
       "Name: SPACEID, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dependent Variable Training Set (Y Training)\n",
    "Y_train = depVar[: 1000]\n",
    "Y_train_count = len(Y_train.index)\n",
    "print('The number of observations in the Y training set are:',str(Y_train_count))\n",
    "Y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of observations in the feature testing set is: 300\n",
      "       WAP001  WAP002  WAP003  WAP004  WAP005  WAP006  WAP007  WAP008  WAP009  WAP010   ...    \\\n",
      "19637     100     100     100     100     100     100     100     100     100     100   ...     \n",
      "19638     100     100     100     100     100     100     100     100     100     100   ...     \n",
      "19639     100     100     100     100     100     100     100     100     100     100   ...     \n",
      "19640     100     100     100     100     100     100     100     100     100     100   ...     \n",
      "19641     100     100     100     100     100     100     100     100     100     100   ...     \n",
      "\n",
      "       WAP511  WAP512  WAP513  WAP514  WAP515  WAP516  WAP517  WAP518  WAP519  WAP520  \n",
      "19637     100     100     100     100     100     100     100     100     100     100  \n",
      "19638     100     100     100     100     100     100     100     100     100     100  \n",
      "19639     100     100     100     100     100     100     100     100     100     100  \n",
      "19640     100     100     100     100     100     100     100     100     100     100  \n",
      "19641     100     100     100     100     100     100     100     100     100     100  \n",
      "\n",
      "[5 rows x 520 columns]\n"
     ]
    }
   ],
   "source": [
    "#Testing Set (X Testing)\n",
    "X_test = features[-300:]\n",
    "X_test_count = len(X_test.index)\n",
    "print('The number of observations in the feature testing set is:',str(X_test_count))\n",
    "print(X_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of observations in the Y training set are: 300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19637    116\n",
       "19638    102\n",
       "19639    102\n",
       "19640    104\n",
       "19641    104\n",
       "Name: SPACEID, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ground Truth (y_test) \n",
    "Y_test = depVar[-300:]\n",
    "Y_test_count = len(Y_test.index)\n",
    "print('The number of observations in the Y training set are:',str(Y_test_count))\n",
    "Y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((750, 520), (250, 520))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split-out validation dataset\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_train, Y_train)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use 10-fold cross validation to estimate accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test options and evaluation metric\n",
    "num_folds = 10\n",
    "seed = 7\n",
    "scoring = 'accuracy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Models. Evaluate six algorithms including simple linear(LR and LDA) and 4 nonlinear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spot-Check Algorithms\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression())) \n",
    "models.append(('LDA', LinearDiscriminantAnalysis())) \n",
    "models.append(('KNN', KNeighborsClassifier())) \n",
    "models.append(('CART', DecisionTreeClassifier())) \n",
    "models.append(('NB', GaussianNB())) \n",
    "models.append(('SVM', SVC()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train suite of algorithms and select best models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.605333 (0.048148)\n",
      "LDA: 0.592000 (0.070098)\n",
      "KNN: 0.564000 (0.036295)\n",
      "CART: 0.604000 (0.048826)\n",
      "NB: 0.634667 (0.045490)\n",
      "SVM: 0.062667 (0.027358)\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "  kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "  cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "  results.append(cv_results)\n",
    "  names.append(name)\n",
    "  msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "  print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare Algorithms\n",
    "fig = pyplot.figure() \n",
    "fig.suptitle('Algorithm Comparison') \n",
    "ax = fig.add_subplot(111) \n",
    "pyplot.boxplot(results) \n",
    "ax.set_xticklabels(names)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stardardize dataset and rerun algorithms to evaluate improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScaledLR: 0.634667 (0.043081)\n",
      "ScaledLDA: 0.485333 (0.241933)\n",
      "ScaledKNN: 0.513333 (0.050684)\n",
      "ScaledCART: 0.602667 (0.054910)\n",
      "ScaledNB: 0.613333 (0.040000)\n",
      "ScaledSVM: 0.381333 (0.045879)\n"
     ]
    }
   ],
   "source": [
    "# Standardize the dataset\n",
    "pipelines = []\n",
    "pipelines.append(('ScaledLR', Pipeline([('Scaler', StandardScaler()),('LR', LogisticRegression())])))\n",
    "pipelines.append(('ScaledLDA', Pipeline([('Scaler', StandardScaler()),('LDA', LinearDiscriminantAnalysis())])))\n",
    "pipelines.append(('ScaledKNN', Pipeline([('Scaler', StandardScaler()),('KNN', KNeighborsClassifier())])))\n",
    "pipelines.append(('ScaledCART', Pipeline([('Scaler', StandardScaler()),('CART', DecisionTreeClassifier())])))\n",
    "pipelines.append(('ScaledNB', Pipeline([('Scaler', StandardScaler()),('NB', GaussianNB())])))\n",
    "pipelines.append(('ScaledSVM', Pipeline([('Scaler', StandardScaler()),('SVM', SVC())]))) \n",
    "results = []\n",
    "names = []\n",
    "for name, model in pipelines:\n",
    "  kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "  cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "  results.append(cv_results)\n",
    "  names.append(name)\n",
    "  msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "  print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare Algorithms\n",
    "fig = pyplot.figure()\n",
    "fig.suptitle('Scaled Algorithm Comparison') \n",
    "ax = fig.add_subplot(111) \n",
    "pyplot.boxplot(results) \n",
    "ax.set_xticklabels(names)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune a couple of algorithms to see if results improve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.640000 using {'n_neighbors': 1}\n",
      "0.640000 (0.042583) with: {'n_neighbors': 1}\n",
      "0.329333 (0.047347) with: {'n_neighbors': 15}\n",
      "0.282667 (0.035678) with: {'n_neighbors': 21}\n",
      "0.252000 (0.051450) with: {'n_neighbors': 25}\n"
     ]
    }
   ],
   "source": [
    "# Tune scaled KNN\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)\n",
    "neighbors = [1,15,21,25]\n",
    "param_grid = dict(n_neighbors=neighbors)\n",
    "model = KNeighborsClassifier()\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
    "grid_result = grid.fit(rescaledX, Y_train)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score'] \n",
    "stds = grid_result.cv_results_['std_test_score'] \n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.644000 using {'C': 0.1, 'kernel': 'linear'}\n",
      "0.644000 (0.038204) with: {'C': 0.1, 'kernel': 'linear'}\n",
      "0.049333 (0.023132) with: {'C': 0.1, 'kernel': 'poly'}\n",
      "0.034667 (0.016000) with: {'C': 0.1, 'kernel': 'rbf'}\n",
      "0.038667 (0.016275) with: {'C': 0.1, 'kernel': 'sigmoid'}\n",
      "0.638667 (0.040200) with: {'C': 0.5, 'kernel': 'linear'}\n",
      "0.069333 (0.017689) with: {'C': 0.5, 'kernel': 'poly'}\n",
      "0.248000 (0.034358) with: {'C': 0.5, 'kernel': 'rbf'}\n",
      "0.173333 (0.027968) with: {'C': 0.5, 'kernel': 'sigmoid'}\n",
      "0.638667 (0.041505) with: {'C': 1.0, 'kernel': 'linear'}\n",
      "0.097333 (0.020699) with: {'C': 1.0, 'kernel': 'poly'}\n",
      "0.368000 (0.047777) with: {'C': 1.0, 'kernel': 'rbf'}\n",
      "0.285333 (0.031098) with: {'C': 1.0, 'kernel': 'sigmoid'}\n",
      "0.637333 (0.039010) with: {'C': 1.5, 'kernel': 'linear'}\n",
      "0.118667 (0.026297) with: {'C': 1.5, 'kernel': 'poly'}\n",
      "0.446667 (0.052747) with: {'C': 1.5, 'kernel': 'rbf'}\n",
      "0.341333 (0.050315) with: {'C': 1.5, 'kernel': 'sigmoid'}\n"
     ]
    }
   ],
   "source": [
    "# Tune scaled SVM\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)\n",
    "c_values = [0.1, 0.5, 1.0, 1.5]\n",
    "kernel_values = ['linear', 'poly','rbf', 'sigmoid']\n",
    "param_grid = dict(C=c_values, kernel=kernel_values)\n",
    "model = SVC()\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold) \n",
    "grid_result = grid.fit(rescaledX, Y_train)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train ensembles and compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AB: 0.096000 (0.058667)\n",
      "GBM: 0.570667 (0.044939)\n",
      "RF: 0.752000 (0.043492)\n"
     ]
    }
   ],
   "source": [
    "# ensembles\n",
    "ensembles = []\n",
    "ensembles.append(('AB', AdaBoostClassifier())) \n",
    "ensembles.append(('GBM', GradientBoostingClassifier())) \n",
    "ensembles.append(('RF', RandomForestClassifier())) \n",
    "results = []\n",
    "names = []\n",
    "for name, model in ensembles:\n",
    "  kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "  cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "  results.append(cv_results)\n",
    "  names.append(name)\n",
    "  msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "  print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare Algorithms\n",
    "fig = pyplot.figure()\n",
    "fig.suptitle('Ensemble Algorithm Comparison') \n",
    "ax = fig.add_subplot(111) \n",
    "pyplot.boxplot(results) \n",
    "ax.set_xticklabels(names)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.700\n",
      "[[4 0 0 ... 0 0 0]\n",
      " [1 3 0 ... 0 0 0]\n",
      " [1 0 1 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 3 0 0]\n",
      " [0 0 0 ... 0 6 0]\n",
      " [0 0 0 ... 0 0 3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.67      0.80      0.73         5\n",
      "           3       1.00      0.60      0.75         5\n",
      "           4       1.00      0.50      0.67         2\n",
      "           5       1.00      1.00      1.00         2\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.67      1.00      0.80         2\n",
      "           8       0.50      1.00      0.67         1\n",
      "           9       1.00      0.67      0.80         3\n",
      "          10       1.00      1.00      1.00         1\n",
      "          15       1.00      0.50      0.67         8\n",
      "          16       0.57      0.80      0.67         5\n",
      "          17       0.75      1.00      0.86         3\n",
      "          18       0.83      1.00      0.91         5\n",
      "          22       1.00      1.00      1.00         3\n",
      "          26       1.00      1.00      1.00         1\n",
      "          27       1.00      1.00      1.00         2\n",
      "          28       1.00      0.50      0.67         4\n",
      "          29       0.33      1.00      0.50         2\n",
      "         101       0.40      0.67      0.50         3\n",
      "         102       1.00      0.33      0.50         3\n",
      "         103       1.00      0.71      0.83         7\n",
      "         104       1.00      1.00      1.00         6\n",
      "         105       0.33      1.00      0.50         1\n",
      "         106       0.75      0.75      0.75         4\n",
      "         107       1.00      0.60      0.75         5\n",
      "         108       0.60      1.00      0.75         3\n",
      "         111       1.00      0.75      0.86         4\n",
      "         112       0.75      1.00      0.86         3\n",
      "         117       1.00      1.00      1.00         3\n",
      "         121       0.00      0.00      0.00         1\n",
      "         122       0.00      0.00      0.00         0\n",
      "         201       0.50      0.56      0.53         9\n",
      "         202       0.50      0.67      0.57         3\n",
      "         203       0.67      1.00      0.80         2\n",
      "         204       1.00      0.50      0.67         2\n",
      "         205       1.00      0.33      0.50         3\n",
      "         206       1.00      1.00      1.00         2\n",
      "         208       1.00      1.00      1.00         1\n",
      "         209       1.00      0.25      0.40         4\n",
      "         210       0.50      0.50      0.50         2\n",
      "         211       0.50      0.67      0.57         3\n",
      "         212       1.00      1.00      1.00         1\n",
      "         213       1.00      0.50      0.67         4\n",
      "         214       0.67      1.00      0.80         2\n",
      "         215       0.18      1.00      0.31         2\n",
      "         216       1.00      0.62      0.77         8\n",
      "         217       0.88      1.00      0.93         7\n",
      "         218       1.00      1.00      1.00         1\n",
      "         219       0.50      1.00      0.67         1\n",
      "         220       0.50      0.33      0.40         3\n",
      "         221       1.00      1.00      1.00         2\n",
      "         222       0.75      1.00      0.86         3\n",
      "         223       0.50      0.62      0.56         8\n",
      "         224       1.00      0.50      0.67         4\n",
      "         225       0.50      1.00      0.67         1\n",
      "         226       1.00      1.00      1.00         1\n",
      "         227       1.00      0.60      0.75         5\n",
      "         228       0.00      0.00      0.00         1\n",
      "         229       0.00      0.00      0.00         3\n",
      "         230       0.83      0.83      0.83         6\n",
      "         231       1.00      1.00      1.00         2\n",
      "         232       1.00      1.00      1.00         1\n",
      "         233       1.00      1.00      1.00         2\n",
      "         234       0.33      0.33      0.33         3\n",
      "         235       1.00      1.00      1.00         1\n",
      "         236       1.00      0.80      0.89         5\n",
      "         237       0.00      0.00      0.00         2\n",
      "         238       0.00      0.00      0.00         2\n",
      "         239       1.00      0.33      0.50         3\n",
      "         240       1.00      0.67      0.80         3\n",
      "         241       0.60      1.00      0.75         3\n",
      "         242       0.43      0.75      0.55         4\n",
      "         243       0.67      0.67      0.67         6\n",
      "         244       1.00      0.20      0.33         5\n",
      "         245       0.00      0.00      0.00         2\n",
      "         246       0.17      0.50      0.25         2\n",
      "         247       1.00      1.00      1.00         3\n",
      "         248       1.00      1.00      1.00         6\n",
      "         250       0.75      1.00      0.86         3\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       250\n",
      "   macro avg       0.72      0.71      0.67       250\n",
      "weighted avg       0.78      0.70      0.70       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Make Predictions with NaiveBayes\n",
    "NB = GaussianNB()\n",
    "NB.fit(X_train, Y_train)\n",
    "predictions = NB.predict(X_test)\n",
    "predAccuracy = accuracy_score(Y_test,predictions)\n",
    "print('Accuracy: %.3f' % predAccuracy)\n",
    "print(confusion_matrix(Y_test, predictions))\n",
    "print(classification_report(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.652\n",
      "[[2 0 0 ... 0 0 0]\n",
      " [1 2 2 ... 0 0 0]\n",
      " [0 0 2 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 2 1 0]\n",
      " [0 0 0 ... 0 5 0]\n",
      " [0 0 0 ... 0 0 3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.67      0.40      0.50         5\n",
      "           3       1.00      0.40      0.57         5\n",
      "           4       0.50      1.00      0.67         2\n",
      "           5       1.00      1.00      1.00         2\n",
      "           6       1.00      1.00      1.00         1\n",
      "           7       1.00      1.00      1.00         2\n",
      "           8       0.50      1.00      0.67         1\n",
      "           9       0.50      0.67      0.57         3\n",
      "          10       1.00      1.00      1.00         1\n",
      "          15       1.00      0.88      0.93         8\n",
      "          16       0.50      0.20      0.29         5\n",
      "          17       0.67      0.67      0.67         3\n",
      "          18       0.80      0.80      0.80         5\n",
      "          22       0.43      1.00      0.60         3\n",
      "          26       0.50      1.00      0.67         1\n",
      "          27       1.00      1.00      1.00         2\n",
      "          28       0.67      1.00      0.80         4\n",
      "          29       1.00      1.00      1.00         2\n",
      "         101       0.40      0.67      0.50         3\n",
      "         102       0.00      0.00      0.00         3\n",
      "         103       0.83      0.71      0.77         7\n",
      "         104       1.00      1.00      1.00         6\n",
      "         105       0.33      1.00      0.50         1\n",
      "         106       0.75      0.75      0.75         4\n",
      "         107       0.75      0.60      0.67         5\n",
      "         108       1.00      0.67      0.80         3\n",
      "         109       0.00      0.00      0.00         0\n",
      "         110       0.00      0.00      0.00         0\n",
      "         111       1.00      0.75      0.86         4\n",
      "         112       0.50      0.67      0.57         3\n",
      "         117       1.00      1.00      1.00         3\n",
      "         121       0.00      0.00      0.00         1\n",
      "         122       0.00      0.00      0.00         0\n",
      "         201       1.00      0.44      0.62         9\n",
      "         202       0.75      1.00      0.86         3\n",
      "         203       0.50      0.50      0.50         2\n",
      "         204       0.33      0.50      0.40         2\n",
      "         205       1.00      0.67      0.80         3\n",
      "         206       1.00      0.50      0.67         2\n",
      "         207       0.00      0.00      0.00         0\n",
      "         208       0.20      1.00      0.33         1\n",
      "         209       1.00      0.25      0.40         4\n",
      "         210       0.00      0.00      0.00         2\n",
      "         211       0.67      0.67      0.67         3\n",
      "         212       0.50      1.00      0.67         1\n",
      "         213       1.00      0.25      0.40         4\n",
      "         214       0.50      1.00      0.67         2\n",
      "         215       0.50      0.50      0.50         2\n",
      "         216       1.00      0.12      0.22         8\n",
      "         217       1.00      0.57      0.73         7\n",
      "         218       0.25      1.00      0.40         1\n",
      "         219       0.17      1.00      0.29         1\n",
      "         220       1.00      1.00      1.00         3\n",
      "         221       0.50      0.50      0.50         2\n",
      "         222       0.33      0.67      0.44         3\n",
      "         223       1.00      0.50      0.67         8\n",
      "         224       1.00      0.75      0.86         4\n",
      "         225       0.00      0.00      0.00         1\n",
      "         226       1.00      1.00      1.00         1\n",
      "         227       0.67      0.40      0.50         5\n",
      "         228       1.00      1.00      1.00         1\n",
      "         229       0.67      0.67      0.67         3\n",
      "         230       0.86      1.00      0.92         6\n",
      "         231       1.00      0.50      0.67         2\n",
      "         232       0.00      0.00      0.00         1\n",
      "         233       0.50      0.50      0.50         2\n",
      "         234       0.60      1.00      0.75         3\n",
      "         235       1.00      1.00      1.00         1\n",
      "         236       0.67      0.80      0.73         5\n",
      "         237       1.00      0.50      0.67         2\n",
      "         238       0.50      0.50      0.50         2\n",
      "         239       0.33      0.33      0.33         3\n",
      "         240       1.00      0.67      0.80         3\n",
      "         241       0.67      0.67      0.67         3\n",
      "         242       0.57      1.00      0.73         4\n",
      "         243       1.00      0.83      0.91         6\n",
      "         244       0.00      0.00      0.00         5\n",
      "         245       0.33      0.50      0.40         2\n",
      "         246       0.40      1.00      0.57         2\n",
      "         247       1.00      0.67      0.80         3\n",
      "         248       0.83      0.83      0.83         6\n",
      "         250       0.43      1.00      0.60         3\n",
      "\n",
      "   micro avg       0.65      0.65      0.65       250\n",
      "   macro avg       0.64      0.65      0.60       250\n",
      "weighted avg       0.75      0.65      0.65       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Make Predictions with LDA\n",
    "LDA = LinearDiscriminantAnalysis()\n",
    "LDA.fit(X_train, Y_train)\n",
    "predictions = LDA.predict(X_test)\n",
    "predAccuracy = accuracy_score(Y_test,predictions)\n",
    "print('Accuracy: %.3f' % predAccuracy)\n",
    "print(confusion_matrix(Y_test, predictions))\n",
    "print(classification_report(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.708\n",
      "[[4 0 0 ... 0 0 0]\n",
      " [1 0 1 ... 0 0 0]\n",
      " [0 0 2 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 2 0 0]\n",
      " [0 0 0 ... 0 3 0]\n",
      " [0 0 0 ... 0 0 2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.80      0.80      0.80         5\n",
      "           3       0.00      0.00      0.00         5\n",
      "           4       0.67      1.00      0.80         2\n",
      "           5       0.67      1.00      0.80         2\n",
      "           6       1.00      1.00      1.00         1\n",
      "           7       1.00      1.00      1.00         2\n",
      "           8       0.20      1.00      0.33         1\n",
      "           9       1.00      0.67      0.80         3\n",
      "          10       0.50      1.00      0.67         1\n",
      "          15       1.00      0.75      0.86         8\n",
      "          16       0.80      0.80      0.80         5\n",
      "          17       1.00      0.67      0.80         3\n",
      "          18       0.80      0.80      0.80         5\n",
      "          22       1.00      1.00      1.00         3\n",
      "          26       1.00      1.00      1.00         1\n",
      "          27       0.50      0.50      0.50         2\n",
      "          28       0.80      1.00      0.89         4\n",
      "          29       0.50      1.00      0.67         2\n",
      "         101       0.75      1.00      0.86         3\n",
      "         102       1.00      0.33      0.50         3\n",
      "         103       0.88      1.00      0.93         7\n",
      "         104       1.00      1.00      1.00         6\n",
      "         105       1.00      1.00      1.00         1\n",
      "         106       1.00      1.00      1.00         4\n",
      "         107       1.00      1.00      1.00         5\n",
      "         108       0.67      0.67      0.67         3\n",
      "         109       0.00      0.00      0.00         0\n",
      "         111       1.00      0.25      0.40         4\n",
      "         112       1.00      1.00      1.00         3\n",
      "         117       1.00      1.00      1.00         3\n",
      "         121       0.00      0.00      0.00         1\n",
      "         122       0.00      0.00      0.00         0\n",
      "         201       0.67      0.44      0.53         9\n",
      "         202       0.50      0.67      0.57         3\n",
      "         203       0.25      0.50      0.33         2\n",
      "         204       1.00      0.50      0.67         2\n",
      "         205       1.00      0.33      0.50         3\n",
      "         206       1.00      1.00      1.00         2\n",
      "         207       0.00      0.00      0.00         0\n",
      "         208       1.00      1.00      1.00         1\n",
      "         209       1.00      0.50      0.67         4\n",
      "         210       1.00      1.00      1.00         2\n",
      "         211       1.00      0.67      0.80         3\n",
      "         212       1.00      1.00      1.00         1\n",
      "         213       1.00      0.75      0.86         4\n",
      "         214       0.50      1.00      0.67         2\n",
      "         215       1.00      1.00      1.00         2\n",
      "         216       1.00      0.75      0.86         8\n",
      "         217       1.00      0.86      0.92         7\n",
      "         218       0.00      0.00      0.00         1\n",
      "         219       1.00      1.00      1.00         1\n",
      "         220       0.50      0.33      0.40         3\n",
      "         221       0.29      1.00      0.44         2\n",
      "         222       1.00      0.67      0.80         3\n",
      "         223       1.00      0.62      0.77         8\n",
      "         224       0.75      0.75      0.75         4\n",
      "         225       0.00      0.00      0.00         1\n",
      "         226       0.00      0.00      0.00         1\n",
      "         227       0.40      0.40      0.40         5\n",
      "         228       0.50      1.00      0.67         1\n",
      "         229       0.67      0.67      0.67         3\n",
      "         230       0.86      1.00      0.92         6\n",
      "         231       1.00      1.00      1.00         2\n",
      "         232       0.33      1.00      0.50         1\n",
      "         233       1.00      0.50      0.67         2\n",
      "         234       1.00      0.67      0.80         3\n",
      "         235       0.50      1.00      0.67         1\n",
      "         236       0.80      0.80      0.80         5\n",
      "         237       0.50      0.50      0.50         2\n",
      "         238       0.00      0.00      0.00         2\n",
      "         239       1.00      0.33      0.50         3\n",
      "         240       0.75      1.00      0.86         3\n",
      "         241       1.00      0.67      0.80         3\n",
      "         242       0.80      1.00      0.89         4\n",
      "         243       1.00      0.83      0.91         6\n",
      "         244       1.00      0.20      0.33         5\n",
      "         245       0.00      0.00      0.00         2\n",
      "         246       0.25      0.50      0.33         2\n",
      "         247       1.00      0.67      0.80         3\n",
      "         248       1.00      0.50      0.67         6\n",
      "         250       0.29      0.67      0.40         3\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       250\n",
      "   macro avg       0.71      0.68      0.66       250\n",
      "weighted avg       0.81      0.71      0.72       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RF = RandomForestClassifier()\n",
    "RF.fit(X_train, Y_train)\n",
    "predictions = RF.predict(X_test)\n",
    "predAccuracy = accuracy_score(Y_test,predictions)\n",
    "print('Accuracy: %.3f' % predAccuracy)\n",
    "print(confusion_matrix(Y_test, predictions))\n",
    "print(classification_report(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kappa: 0.647\n",
      "[[2 0 0 ... 0 0 0]\n",
      " [1 2 2 ... 0 0 0]\n",
      " [0 0 2 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 2 1 0]\n",
      " [0 0 0 ... 0 5 0]\n",
      " [0 0 0 ... 0 0 3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.67      0.40      0.50         5\n",
      "           3       1.00      0.40      0.57         5\n",
      "           4       0.50      1.00      0.67         2\n",
      "           5       1.00      1.00      1.00         2\n",
      "           6       1.00      1.00      1.00         1\n",
      "           7       1.00      1.00      1.00         2\n",
      "           8       0.50      1.00      0.67         1\n",
      "           9       0.50      0.67      0.57         3\n",
      "          10       1.00      1.00      1.00         1\n",
      "          15       1.00      0.88      0.93         8\n",
      "          16       0.50      0.20      0.29         5\n",
      "          17       0.67      0.67      0.67         3\n",
      "          18       0.80      0.80      0.80         5\n",
      "          22       0.43      1.00      0.60         3\n",
      "          26       0.50      1.00      0.67         1\n",
      "          27       1.00      1.00      1.00         2\n",
      "          28       0.67      1.00      0.80         4\n",
      "          29       1.00      1.00      1.00         2\n",
      "         101       0.40      0.67      0.50         3\n",
      "         102       0.00      0.00      0.00         3\n",
      "         103       0.83      0.71      0.77         7\n",
      "         104       1.00      1.00      1.00         6\n",
      "         105       0.33      1.00      0.50         1\n",
      "         106       0.75      0.75      0.75         4\n",
      "         107       0.75      0.60      0.67         5\n",
      "         108       1.00      0.67      0.80         3\n",
      "         109       0.00      0.00      0.00         0\n",
      "         110       0.00      0.00      0.00         0\n",
      "         111       1.00      0.75      0.86         4\n",
      "         112       0.50      0.67      0.57         3\n",
      "         117       1.00      1.00      1.00         3\n",
      "         121       0.00      0.00      0.00         1\n",
      "         122       0.00      0.00      0.00         0\n",
      "         201       1.00      0.44      0.62         9\n",
      "         202       0.75      1.00      0.86         3\n",
      "         203       0.50      0.50      0.50         2\n",
      "         204       0.33      0.50      0.40         2\n",
      "         205       1.00      0.67      0.80         3\n",
      "         206       1.00      0.50      0.67         2\n",
      "         207       0.00      0.00      0.00         0\n",
      "         208       0.20      1.00      0.33         1\n",
      "         209       1.00      0.25      0.40         4\n",
      "         210       0.00      0.00      0.00         2\n",
      "         211       0.67      0.67      0.67         3\n",
      "         212       0.50      1.00      0.67         1\n",
      "         213       1.00      0.25      0.40         4\n",
      "         214       0.50      1.00      0.67         2\n",
      "         215       0.50      0.50      0.50         2\n",
      "         216       1.00      0.12      0.22         8\n",
      "         217       1.00      0.57      0.73         7\n",
      "         218       0.25      1.00      0.40         1\n",
      "         219       0.17      1.00      0.29         1\n",
      "         220       1.00      1.00      1.00         3\n",
      "         221       0.50      0.50      0.50         2\n",
      "         222       0.33      0.67      0.44         3\n",
      "         223       1.00      0.50      0.67         8\n",
      "         224       1.00      0.75      0.86         4\n",
      "         225       0.00      0.00      0.00         1\n",
      "         226       1.00      1.00      1.00         1\n",
      "         227       0.67      0.40      0.50         5\n",
      "         228       1.00      1.00      1.00         1\n",
      "         229       0.67      0.67      0.67         3\n",
      "         230       0.86      1.00      0.92         6\n",
      "         231       1.00      0.50      0.67         2\n",
      "         232       0.00      0.00      0.00         1\n",
      "         233       0.50      0.50      0.50         2\n",
      "         234       0.60      1.00      0.75         3\n",
      "         235       1.00      1.00      1.00         1\n",
      "         236       0.67      0.80      0.73         5\n",
      "         237       1.00      0.50      0.67         2\n",
      "         238       0.50      0.50      0.50         2\n",
      "         239       0.33      0.33      0.33         3\n",
      "         240       1.00      0.67      0.80         3\n",
      "         241       0.67      0.67      0.67         3\n",
      "         242       0.57      1.00      0.73         4\n",
      "         243       1.00      0.83      0.91         6\n",
      "         244       0.00      0.00      0.00         5\n",
      "         245       0.33      0.50      0.40         2\n",
      "         246       0.40      1.00      0.57         2\n",
      "         247       1.00      0.67      0.80         3\n",
      "         248       0.83      0.83      0.83         6\n",
      "         250       0.43      1.00      0.60         3\n",
      "\n",
      "   micro avg       0.65      0.65      0.65       250\n",
      "   macro avg       0.64      0.65      0.60       250\n",
      "weighted avg       0.75      0.65      0.65       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LDA = LinearDiscriminantAnalysis()\n",
    "LDA.fit(X_train, Y_train)\n",
    "predictions = LDA.predict(X_test)\n",
    "predKappa = cohen_kappa_score(Y_test,predictions)\n",
    "print('Kappa: %.3f' % predKappa)\n",
    "print(confusion_matrix(Y_test, predictions))\n",
    "print(classification_report(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kappa: 0.695\n",
      "[[4 0 0 ... 0 0 0]\n",
      " [1 3 0 ... 0 0 0]\n",
      " [1 0 1 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 3 0 0]\n",
      " [0 0 0 ... 0 6 0]\n",
      " [0 0 0 ... 0 0 3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.67      0.80      0.73         5\n",
      "           3       1.00      0.60      0.75         5\n",
      "           4       1.00      0.50      0.67         2\n",
      "           5       1.00      1.00      1.00         2\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.67      1.00      0.80         2\n",
      "           8       0.50      1.00      0.67         1\n",
      "           9       1.00      0.67      0.80         3\n",
      "          10       1.00      1.00      1.00         1\n",
      "          15       1.00      0.50      0.67         8\n",
      "          16       0.57      0.80      0.67         5\n",
      "          17       0.75      1.00      0.86         3\n",
      "          18       0.83      1.00      0.91         5\n",
      "          22       1.00      1.00      1.00         3\n",
      "          26       1.00      1.00      1.00         1\n",
      "          27       1.00      1.00      1.00         2\n",
      "          28       1.00      0.50      0.67         4\n",
      "          29       0.33      1.00      0.50         2\n",
      "         101       0.40      0.67      0.50         3\n",
      "         102       1.00      0.33      0.50         3\n",
      "         103       1.00      0.71      0.83         7\n",
      "         104       1.00      1.00      1.00         6\n",
      "         105       0.33      1.00      0.50         1\n",
      "         106       0.75      0.75      0.75         4\n",
      "         107       1.00      0.60      0.75         5\n",
      "         108       0.60      1.00      0.75         3\n",
      "         111       1.00      0.75      0.86         4\n",
      "         112       0.75      1.00      0.86         3\n",
      "         117       1.00      1.00      1.00         3\n",
      "         121       0.00      0.00      0.00         1\n",
      "         122       0.00      0.00      0.00         0\n",
      "         201       0.50      0.56      0.53         9\n",
      "         202       0.50      0.67      0.57         3\n",
      "         203       0.67      1.00      0.80         2\n",
      "         204       1.00      0.50      0.67         2\n",
      "         205       1.00      0.33      0.50         3\n",
      "         206       1.00      1.00      1.00         2\n",
      "         208       1.00      1.00      1.00         1\n",
      "         209       1.00      0.25      0.40         4\n",
      "         210       0.50      0.50      0.50         2\n",
      "         211       0.50      0.67      0.57         3\n",
      "         212       1.00      1.00      1.00         1\n",
      "         213       1.00      0.50      0.67         4\n",
      "         214       0.67      1.00      0.80         2\n",
      "         215       0.18      1.00      0.31         2\n",
      "         216       1.00      0.62      0.77         8\n",
      "         217       0.88      1.00      0.93         7\n",
      "         218       1.00      1.00      1.00         1\n",
      "         219       0.50      1.00      0.67         1\n",
      "         220       0.50      0.33      0.40         3\n",
      "         221       1.00      1.00      1.00         2\n",
      "         222       0.75      1.00      0.86         3\n",
      "         223       0.50      0.62      0.56         8\n",
      "         224       1.00      0.50      0.67         4\n",
      "         225       0.50      1.00      0.67         1\n",
      "         226       1.00      1.00      1.00         1\n",
      "         227       1.00      0.60      0.75         5\n",
      "         228       0.00      0.00      0.00         1\n",
      "         229       0.00      0.00      0.00         3\n",
      "         230       0.83      0.83      0.83         6\n",
      "         231       1.00      1.00      1.00         2\n",
      "         232       1.00      1.00      1.00         1\n",
      "         233       1.00      1.00      1.00         2\n",
      "         234       0.33      0.33      0.33         3\n",
      "         235       1.00      1.00      1.00         1\n",
      "         236       1.00      0.80      0.89         5\n",
      "         237       0.00      0.00      0.00         2\n",
      "         238       0.00      0.00      0.00         2\n",
      "         239       1.00      0.33      0.50         3\n",
      "         240       1.00      0.67      0.80         3\n",
      "         241       0.60      1.00      0.75         3\n",
      "         242       0.43      0.75      0.55         4\n",
      "         243       0.67      0.67      0.67         6\n",
      "         244       1.00      0.20      0.33         5\n",
      "         245       0.00      0.00      0.00         2\n",
      "         246       0.17      0.50      0.25         2\n",
      "         247       1.00      1.00      1.00         3\n",
      "         248       1.00      1.00      1.00         6\n",
      "         250       0.75      1.00      0.86         3\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       250\n",
      "   macro avg       0.72      0.71      0.67       250\n",
      "weighted avg       0.78      0.70      0.70       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NB = GaussianNB()\n",
    "NB.fit(X_train, Y_train)\n",
    "predictions = NB.predict(X_test)\n",
    "predKappa = cohen_kappa_score(Y_test,predictions)\n",
    "print('Kappa: %.3f' % predKappa)\n",
    "print(confusion_matrix(Y_test, predictions))\n",
    "print(classification_report(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kappa: 0.764\n",
      "[[5 0 0 ... 0 0 0]\n",
      " [0 5 0 ... 0 0 0]\n",
      " [0 0 2 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 3 0 0]\n",
      " [0 0 0 ... 0 3 0]\n",
      " [0 0 0 ... 0 0 2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       1.00      1.00      1.00         5\n",
      "           3       1.00      1.00      1.00         5\n",
      "           4       1.00      1.00      1.00         2\n",
      "           5       1.00      1.00      1.00         2\n",
      "           6       1.00      1.00      1.00         1\n",
      "           7       1.00      1.00      1.00         2\n",
      "           8       0.50      1.00      0.67         1\n",
      "           9       1.00      0.67      0.80         3\n",
      "          10       0.50      1.00      0.67         1\n",
      "          15       1.00      0.75      0.86         8\n",
      "          16       1.00      0.80      0.89         5\n",
      "          17       0.75      1.00      0.86         3\n",
      "          18       1.00      0.80      0.89         5\n",
      "          22       1.00      1.00      1.00         3\n",
      "          26       1.00      1.00      1.00         1\n",
      "          27       0.50      0.50      0.50         2\n",
      "          28       0.75      0.75      0.75         4\n",
      "          29       0.50      1.00      0.67         2\n",
      "         101       0.60      1.00      0.75         3\n",
      "         102       1.00      0.67      0.80         3\n",
      "         103       1.00      0.86      0.92         7\n",
      "         104       1.00      1.00      1.00         6\n",
      "         105       1.00      1.00      1.00         1\n",
      "         106       1.00      1.00      1.00         4\n",
      "         107       1.00      1.00      1.00         5\n",
      "         108       1.00      1.00      1.00         3\n",
      "         109       0.00      0.00      0.00         0\n",
      "         110       0.00      0.00      0.00         0\n",
      "         111       1.00      0.25      0.40         4\n",
      "         112       0.75      1.00      0.86         3\n",
      "         117       1.00      1.00      1.00         3\n",
      "         121       0.00      0.00      0.00         1\n",
      "         122       0.00      0.00      0.00         0\n",
      "         201       0.83      0.56      0.67         9\n",
      "         202       1.00      0.67      0.80         3\n",
      "         203       0.29      1.00      0.44         2\n",
      "         204       1.00      1.00      1.00         2\n",
      "         205       1.00      0.67      0.80         3\n",
      "         206       1.00      1.00      1.00         2\n",
      "         207       0.00      0.00      0.00         0\n",
      "         208       0.50      1.00      0.67         1\n",
      "         209       0.67      0.50      0.57         4\n",
      "         210       0.67      1.00      0.80         2\n",
      "         211       0.67      0.67      0.67         3\n",
      "         212       0.00      0.00      0.00         1\n",
      "         213       0.75      0.75      0.75         4\n",
      "         214       1.00      1.00      1.00         2\n",
      "         215       0.67      1.00      0.80         2\n",
      "         216       0.62      0.62      0.62         8\n",
      "         217       1.00      0.86      0.92         7\n",
      "         218       0.33      1.00      0.50         1\n",
      "         219       0.00      0.00      0.00         1\n",
      "         220       1.00      0.33      0.50         3\n",
      "         221       0.25      0.50      0.33         2\n",
      "         222       0.33      0.33      0.33         3\n",
      "         223       0.83      0.62      0.71         8\n",
      "         224       1.00      0.50      0.67         4\n",
      "         225       0.00      0.00      0.00         1\n",
      "         226       0.00      0.00      0.00         1\n",
      "         227       0.75      0.60      0.67         5\n",
      "         228       0.33      1.00      0.50         1\n",
      "         229       0.50      0.67      0.57         3\n",
      "         230       0.86      1.00      0.92         6\n",
      "         231       0.33      0.50      0.40         2\n",
      "         232       1.00      1.00      1.00         1\n",
      "         233       0.50      0.50      0.50         2\n",
      "         234       0.75      1.00      0.86         3\n",
      "         235       0.00      0.00      0.00         1\n",
      "         236       1.00      1.00      1.00         5\n",
      "         237       0.67      1.00      0.80         2\n",
      "         238       0.50      0.50      0.50         2\n",
      "         239       1.00      0.67      0.80         3\n",
      "         240       0.75      1.00      0.86         3\n",
      "         241       1.00      0.67      0.80         3\n",
      "         242       0.80      1.00      0.89         4\n",
      "         243       0.83      0.83      0.83         6\n",
      "         244       1.00      0.40      0.57         5\n",
      "         245       0.67      1.00      0.80         2\n",
      "         246       1.00      1.00      1.00         2\n",
      "         247       1.00      1.00      1.00         3\n",
      "         248       1.00      0.50      0.67         6\n",
      "         250       0.67      0.67      0.67         3\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       250\n",
      "   macro avg       0.71      0.72      0.69       250\n",
      "weighted avg       0.83      0.77      0.77       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RF = RandomForestClassifier()\n",
    "RF.fit(X_train, Y_train)\n",
    "predictions = RF.predict(X_test)\n",
    "predKappa = cohen_kappa_score(Y_test,predictions)\n",
    "print('Kappa: %.3f' % predKappa)\n",
    "print(confusion_matrix(Y_test, predictions))\n",
    "print(classification_report(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
